{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "# import htk_featio as htk\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout  # Activation, Flatten\n",
    "# from keras.callbacks import EarlyStopping\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = '/home/spilborghs/Documents/SER_DB/enterface_database/AUDIO_ONLY/'\n",
    "PATH = '/home/ferreiraa/Documents/Mestrado/agender_distribution/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feat_extract(files):\n",
    "    file_name = os.path.join(os.path.abspath(PATH+str(files.file)))\n",
    "    # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series\n",
    "    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "    # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,\n",
    "                    axis=0)\n",
    "    # Computes spectral contrast\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)\n",
    "    return mfccs, mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nada, Bt, epoch = sys.argv\n",
    "\n",
    "Bt, epoch = 32, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEAT_PATH = \"/home/spilborghs/Documents/mel_filter_banks_features/feat/Experiments/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_file = pd.read_csv(\"Test_wav.csv\")\n",
    "Test_file = pd.read_csv(\"Test_wav.csv\")\n",
    "Val_file = pd.read_csv(\"Test_wav.csv\")\n",
    "Arq_train = Train_file['Arquive']\n",
    "Arq_test = Test_file['Arquive']\n",
    "Arq_val = Val_file['Arquive']\n",
    "Res_train = Train_file['Results']\n",
    "Res_test = Test_file['Results']\n",
    "Res_val = Val_file['Results']\n",
    "\n",
    "# print(Res_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_train_x = []\n",
    "for i in Arq_train:\n",
    "    if i != 'Arquive':\n",
    "        V_train_x.append(i)\n",
    "\n",
    "V_test_x = []\n",
    "for i in Arq_test:\n",
    "    if i != 'Arquive':\n",
    "        V_test_x.append(i)\n",
    "\n",
    "V_val_x = []\n",
    "for i in Arq_val:\n",
    "    if i != 'Arquive':\n",
    "        V_val_x.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(V_train_x)\n",
    "test_df = pd.DataFrame(V_test_x)\n",
    "val_df = pd.DataFrame(V_val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.rename(columns={0: 'file'})\n",
    "test_df = test_df.rename(columns={0: 'file'})\n",
    "val_df = val_df.rename(columns={0: 'file'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_df.apply(Feat_extract, axis=1)\n",
    "ini_feat = time.time()\n",
    "test_features = test_df.apply(Feat_extract, axis=1)\n",
    "fim_feat = time.time() - ini_feat\n",
    "val_features = val_df.apply(Feat_extract, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = []\n",
    "for i in range(0, len(train_features)):\n",
    "    features_train.append(np.concatenate((\n",
    "        train_features[i][0],\n",
    "        train_features[i][1]), axis=0))\n",
    "\n",
    "features_test = []\n",
    "for i in range(0, len(test_features)):\n",
    "    features_test.append(np.concatenate((\n",
    "        test_features[i][0],\n",
    "        test_features[i][1]), axis=0))\n",
    "\n",
    "features_val = []\n",
    "for i in range(0, len(val_features)):\n",
    "    features_val.append(np.concatenate((\n",
    "        val_features[i][0],\n",
    "        val_features[i][1]), axis=0))\n",
    "    \n",
    "# end of creating df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(features_test)\n",
    "X_train = np.array(features_train)\n",
    "Y_train = np.array(Res_train)\n",
    "X_val = np.array(features_val)\n",
    "Y_val = np.array(Res_val)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "Y_train = to_categorical(lb.fit_transform(Y_train))\n",
    "Y_val = to_categorical(lb.fit_transform(Y_val))\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_val = ss.transform(X_val)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(168, input_shape=(168,), activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(84, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(84, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "#early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_epochs = int(epoch)\n",
    "BSize = int(Bt)\n",
    "ini_train = time.time()\n",
    "history = model.fit(X_train, Y_train, batch_size=BSize, epochs=N_epochs, validation_data=(X_val, Y_val)) #callbacks=[early_stop])\n",
    "model.save(\"model_\"+str(N_epochs)+'_'+str(BSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fim_train = time.time() - ini_train\n",
    "file = open(\"../../Dados_NN/librosaTestes.txt\", 'a+')\n",
    "file.write(\"Teste com \"+str(N_epochs)+\" epocas e \"+str(BSize)+\" de batch: \\n\")\n",
    "file.write(\"Tempo de Retirada de caracteristicas: \" + str((1.0*fim_feat)/len(Res_test))+'\\n')\n",
    "file.write(\"Tempo de Treino: \"+str(fim_train)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out our train accuracy and validation accuracy over epochs\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']  # Set figure size\n",
    "# Generate line plot of training, testing loss over epochs\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(train_accuracy, label='Training Accuracy', color='#185fad')\n",
    "# Set title\n",
    "plt.plot(val_accuracy, label='Validation Accuracy', color='orange')\n",
    "plt.title('Training and Validation Accuracy by Epoch', fontsize=25)\n",
    "plt.xlabel('Epoch', fontsize=18)\n",
    "plt.ylabel('Categorical Crossentropy', fontsize=18)\n",
    "plt.xticks(range(0, int(N_epochs), int(N_epochs/20)), range(0, int(N_epochs),\n",
    "                                                            int(N_epochs/20)))\n",
    "plt.legend(fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.show()\n",
    "ini_test = time.time()\n",
    "# We get our predictions from the test data\n",
    "predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "# We transform back our predictions to the speakers ids\n",
    "#predictions = model.predict_classes(X_test)\n",
    "# Finally, we can add those predictions to our original dataframe\n",
    "predictions = lb.inverse_transform(predictions)\n",
    "test_predict = predictions\n",
    "fim_test = time.time() - ini_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.write(\"Tempo de Teste: \"+str((1.0*fim_test)/len(Res_test))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predict = 0.0\n",
    "ConfMat = [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0],\n",
    "           [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(Res_test)):\n",
    "    if str(test_predict[i]) != 'NaN' and int(test_predict[i]) == int(Res_test[i]):\n",
    "        correct_predict += 1.\n",
    "\n",
    "    ConfMat[Res_test[i]][int(test_predict[i])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A porcentagem de acerto Ã© de : \"+str((correct_predict*100)/len(Res_test))+\"%\")\n",
    "file.write(\"Porcentagem de acerto: \"+str((correct_predict*100)/len(Res_test))+\"%\\n\")\n",
    "file.write('##########\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"/home/spilborghs/Documents/Dados_NN/Librosa_Confusion_matrix.txt\", 'a+')\n",
    "file.write(\"Usando: Batch = \"+str(Bt)+\" | Epochs = \"+str(epoch)+'\\n')\n",
    "for i in ConfMat:\n",
    "    file.write(str(i)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-dev",
   "language": "python",
   "name": "tensorflow-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
