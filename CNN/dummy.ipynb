{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 23:02:27.274554: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-23 23:02:27.274609: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import pathlib\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "import keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = os.path.join(os.path.expanduser(\"~\"),'dataSet/audio/agender_distribution/')\n",
    "NETWORK_ROOT = os.path.join(os.path.expanduser(\"~\"),'Mestrado-PC/github/Conv1D/CNN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pause() function definition.\n",
    "def pause():\n",
    "\twhile True:\n",
    "\t\tif keyboard.read_key() == 'space':\n",
    "\t\t\t# If you put 'space' key\n",
    "\t\t\t# the program will resume.\n",
    "\t\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_fft(audio):\n",
    "    # Since tf.signal.fft applies FFT on the innermost dimension, we need to squeeze the dimensions and then expand them again after FFT\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    fft = tf.signal.fft(tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64))\n",
    "    fft = tf.expand_dims(fft, axis=-1)\n",
    "    # Return the absolute value of the first half of the FFT which represents the positive frequencies\n",
    "    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_audio(path):\n",
    "    # Reads and decodes an audio file\n",
    "    audio = tf.io.read_file(path)\n",
    "    audio, _ = tf.audio.decode_wav(audio, 1, 8000)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_and_labels_to_dataset(audio_paths, labels):\n",
    "    # Constructs a dataset of audios and labels\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
    "    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    return tf.data.Dataset.zip((audio_ds, label_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(npy_path):\n",
    "    npy_content = np.load(npy_path)\n",
    "    return npy_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_and_labels_to_dataset_HTK(paths, labels):\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    array_ds = path_ds.map(lambda x: tf.numpy_function(map_func, [x], tf.float64),num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    return tf.data.Dataset.zip((array_ds, label_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npy_header_offset(npy_path):\n",
    "    with open(str(npy_path), 'rb') as f:\n",
    "        if f.read(6) != b'\\x93NUMPY':\n",
    "            raise ValueError('Invalid NPY file.')\n",
    "        version_major, version_minor = f.read(2)\n",
    "        if version_major == 1:\n",
    "            header_len_size =2\n",
    "        elif version_major == 2:\n",
    "            header_len_size = 4\n",
    "        else:\n",
    "            raise ValueError('Unknown NPY file version {}.{}.'.format(version_major, version_minor))\n",
    "        header_len = sum(b << (8 * i) for i, b in enumerate(f.read(header_len_size)))\n",
    "        header = f.read(header_len)\n",
    "        if not header.endswith(b'\\n'):\n",
    "            raise ValueError('Invalid NPY file.')\n",
    "        return f.tell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_list_path = 'file_lists/3-classes/train_database_full.csv'\n",
    "test_file_list_path = 'file_lists/3-classes/test_database_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_list = pd.read_csv(os.path.join(NETWORK_ROOT, train_file_list_path))\n",
    "train_audio_files = train_file_list['file']\n",
    "train_classes = train_file_list['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_paths = list(train_audio_files)\n",
    "labels = list(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(audio_paths)):\n",
    "    audio_paths[i] = re.sub('.wav', '-n.mfc.csv', audio_paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(audio_paths)):\n",
    "    audio_paths[i] = re.sub('-n.npy', '-n.wav', audio_paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(audio_paths)):\n",
    "    audio_paths[i] = os.path.join(DATASET_ROOT, audio_paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = paths_and_labels_to_dataset(audio_paths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(buffer_size=128 * 8, seed=43).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_ds.take(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in path_ds:\n",
    "    a = tf.io.read_file(element)\n",
    "    # b = tf.io.decode_raw(a, out_type=float, little_endian=False)\n",
    "    print(element)\n",
    "    print(a)\n",
    "    '''b = tf.strings.to_number(tf.strings.split(a, sep=\" \"), tf.float64)\n",
    "    print(type(b))\n",
    "    print(b)'''\n",
    "    input(\"Press any key to terminate the program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_elem = list(batch.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_elem[254][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('conv1d-venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04cedfdd4aaeb3a14b7313c5139a1493a34cd254dccc2367acd55268f3eb1701"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
